# YOLO Detection Pipeline - Complete Flow

## ðŸ”„ Complete Pipeline Overview

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    YOLO DETECTION PIPELINE                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

ðŸ“± Camera / Image Input
   â”‚
   â”‚ CameraImage (YUV420 or BGRA8888)
   â”‚ Original size: variable (e.g., 1920x1080)
   â”‚
   â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  STEP 1: CAMERA IMAGE CAPTURE                               â”‚
â”‚  - Receives live camera frame                               â”‚
â”‚  - Format: YUV420 or BGRA8888                               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
   â”‚
   â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  STEP 2: PREPROCESSING                                      â”‚
â”‚  â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”  â”‚
â”‚  A. Resize                                                  â”‚
â”‚     - Input: Original camera size                           â”‚
â”‚     - Output: 640x640 pixels                                â”‚
â”‚     - Method: Bilinear sampling                             â”‚
â”‚                                                              â”‚
â”‚  B. Color Conversion                                        â”‚
â”‚     - YUV420 â†’ RGB or BGRA â†’ RGB                           â”‚
â”‚     - 3 channels (Red, Green, Blue)                         â”‚
â”‚                                                              â”‚
â”‚  C. Normalization                                           â”‚
â”‚     - Range: 0-255 â†’ 0.0-1.0                               â”‚
â”‚     - Formula: pixel_value / 255.0                          â”‚
â”‚                                                              â”‚
â”‚  Final Format: [1, 640, 640, 3]                            â”‚
â”‚  (batch_size, height, width, channels)                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
   â”‚
   â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  STEP 3: YOLO .TFLITE MODEL INFERENCE                       â”‚
â”‚  â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”  â”‚
â”‚  Model: best_float32.tflite                                 â”‚
â”‚  Type: YOLOv8 (or similar) for currency detection           â”‚
â”‚                                                              â”‚
â”‚  Input Tensor:                                              â”‚
â”‚    Shape: [1, 640, 640, 3]                                 â”‚
â”‚    Type: Float32                                            â”‚
â”‚    Range: 0.0 - 1.0 (normalized RGB)                       â”‚
â”‚                                                              â”‚
â”‚  Processing:                                                â”‚
â”‚    - Feature extraction through CNN layers                  â”‚
â”‚    - Multi-scale detection (80x80, 40x40, 20x20 grids)     â”‚
â”‚    - Anchor-based box predictions                           â”‚
â”‚                                                              â”‚
â”‚  Output Tensor:                                             â”‚
â”‚    Shape: [1, 29, 8400]                                    â”‚
â”‚    - 8400 predictions from all grid cells                   â”‚
â”‚    - 29 values per prediction                               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
   â”‚
   â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  STEP 4: RAW OUTPUTS EXTRACTION                             â”‚
â”‚  â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”  â”‚
â”‚  Output Format: [29, 8400]                                  â”‚
â”‚                                                              â”‚
â”‚  For each of 8400 predictions:                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  Channel 0: X coordinate (center)                    â”‚  â”‚
â”‚  â”‚  Channel 1: Y coordinate (center)                    â”‚  â”‚
â”‚  â”‚  Channel 2: Width of bounding box                    â”‚  â”‚
â”‚  â”‚  Channel 3: Height of bounding box                   â”‚  â”‚
â”‚  â”‚  Channel 4: Objectness confidence (0.0 - 1.0)       â”‚  â”‚
â”‚  â”‚  Channels 5-28: Class scores for 24 classes         â”‚  â”‚
â”‚  â”‚     - 100_front, 100_back, 200_front, etc.          â”‚  â”‚
â”‚  â”‚     - security_thread, Gandhi_portrait, etc.         â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                                              â”‚
â”‚  Parsing Process:                                           â”‚
â”‚    1. Extract bounding box coordinates (x, y, w, h)         â”‚
â”‚    2. Extract confidence score                              â”‚
â”‚    3. Find highest class score â†’ determine class ID         â”‚
â”‚    4. Filter by confidence threshold (>= 0.1)               â”‚
â”‚    5. Create CurrencyDetection objects                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
   â”‚
   â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  STEP 5: POST-PROCESSING (NMS)                              â”‚
â”‚  â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”  â”‚
â”‚  Non-Maximum Suppression (NMS)                              â”‚
â”‚                                                              â”‚
â”‚  Purpose: Remove duplicate/overlapping detections           â”‚
â”‚                                                              â”‚
â”‚  Algorithm:                                                  â”‚
â”‚  1. Sort all detections by confidence (highest first)       â”‚
â”‚                                                              â”‚
â”‚  2. For each detection:                                     â”‚
â”‚     - Keep it as a final detection                          â”‚
â”‚     - Compare with remaining detections                     â”‚
â”‚     - Calculate IoU (Intersection over Union)               â”‚
â”‚     - If IoU > 0.5: suppress the lower confidence box       â”‚
â”‚                                                              â”‚
â”‚  IoU Formula:                                               â”‚
â”‚     IoU = Intersection Area / Union Area                    â”‚
â”‚                                                              â”‚
â”‚  Threshold: 0.5                                             â”‚
â”‚  - IoU >= 0.5: Boxes overlap significantly â†’ suppress       â”‚
â”‚  - IoU < 0.5: Different objects â†’ keep both                 â”‚
â”‚                                                              â”‚
â”‚  Result: Filtered list of unique detections                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
   â”‚
   â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  STEP 6: BOUNDING BOXES ON SCREEN                           â”‚
â”‚  â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”  â”‚
â”‚  Final Detections â†’ Visual Display                          â”‚
â”‚                                                              â”‚
â”‚  For each detection:                                        â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  CurrencyDetection {                                 â”‚  â”‚
â”‚  â”‚    confidence: 0.923,                                â”‚  â”‚
â”‚  â”‚    label: "500_front",                               â”‚  â”‚
â”‚  â”‚    x: 0.5,     // normalized (0-1)                   â”‚  â”‚
â”‚  â”‚    y: 0.5,                                           â”‚  â”‚
â”‚  â”‚    width: 0.3,                                       â”‚  â”‚
â”‚  â”‚    height: 0.2                                       â”‚  â”‚
â”‚  â”‚  }                                                    â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                                              â”‚
â”‚  Rendering (DetectionPainter):                              â”‚
â”‚  1. Scale normalized coords to screen size                  â”‚
â”‚  2. Draw colored rectangle (green for high confidence)      â”‚
â”‚  3. Draw label with confidence percentage                   â”‚
â”‚  4. Update UI in real-time (60 FPS)                         â”‚
â”‚                                                              â”‚
â”‚  Display Elements:                                          â”‚
â”‚  - Bounding box (colored rectangle)                         â”‚
â”‚  - Label text (e.g., "500_front 92.3%")                    â”‚
â”‚  - Detection count panel                                    â”‚
â”‚  - Pipeline status indicator                                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

```

## ðŸ“Š Data Flow Summary

| Step | Input | Output | Processing Time |
|------|-------|--------|-----------------|
| 1. Camera | Live feed | CameraImage | ~16ms (60fps) |
| 2. Preprocessing | Raw image | [1,640,640,3] tensor | ~20-30ms |
| 3. Model Inference | Normalized tensor | [1,29,8400] raw output | ~50-100ms |
| 4. Output Parsing | Raw tensor | List of detections | ~5-10ms |
| 5. NMS | All detections | Filtered detections | ~5ms |
| 6. Display | Detections | Screen rendering | ~16ms (60fps) |

**Total Pipeline: ~100-150ms per frame**

## ðŸŽ¯ Detection Classes (24 Classes)

The model is trained to detect 24 different currency features:

1. `100_back` - â‚¹100 note back side
2. `100_front` - â‚¹100 note front side
3. `200_back` - â‚¹200 note back side
4. `200_front` - â‚¹200 note front side
5. `500_back` - â‚¹500 note back side
6. `500_front` - â‚¹500 note front side
7. `50_back` - â‚¹50 note back side
8. `50_front` - â‚¹50 note front side
9. `Gandhi_potrait` - Gandhi portrait feature
10. `ashoka_piller` - Ashoka pillar symbol
11. `bleed_lines` - Security bleed lines
12. `color_chg_num` - Color-changing number
13. `denomination_back` - Back denomination
14. `guarentee_clause` - Guarantee clause text
15. `language_panel` - Language panel
16. `lined_number` - Lined number feature
17. `micro_text` - Micro-printed text
18. `monumental_portrait` - Monument portrait
19. `note_50_see_throug` - â‚¹50 see-through feature
20. `res_bank` - Reserve Bank text
21. `security_thread` - Security thread
22. `see_through_reg` - See-through registration
23. `serial_number` - Serial number
24. `swatch_bharath` - Swachh Bharat logo
25. `white_number` - White number feature

## ðŸ”§ Configuration Parameters

```dart
// Model Settings
static const int inputSize = 640;           // Input image size
static const double confidenceThreshold = 0.1;  // Minimum confidence
static const double iouThreshold = 0.5;     // NMS overlap threshold

// Frame Processing
int _frameSkipCounter = 0;                  // Skip every other frame
bool _isProcessingFrame = false;            // Prevent concurrent processing
```

## ðŸ“± Implementation Files

1. **YOLODetector** (`lib/services/yolo_detector.dart`)
   - Model loading and initialization
   - Preprocessing (resize, normalize)
   - Model inference
   - Output parsing
   - NMS post-processing

2. **DetectionProvider** (`lib/providers/detection_provider.dart`)
   - State management
   - Frame processing coordination
   - Detection results storage

3. **DetectionPainter** (`lib/painters/detection_painter.dart`)
   - Bounding box rendering
   - Label text display
   - Coordinate scaling

4. **ScannerScreen** (`lib/screens/scanner_screen.dart`)
   - Camera stream handling
   - Real-time detection display
   - Pipeline status visualization

## ðŸš€ Performance Optimizations

1. **Frame Skipping**: Process every 2nd frame to reduce CPU load
2. **Concurrent Prevention**: Only one frame processed at a time
3. **Efficient Memory**: Reuse tensor buffers where possible
4. **Optimized Model**: Float32 TFLite for balance of speed/accuracy

## ðŸ“ˆ Expected Results

- **Detection Speed**: 10-15 FPS on mobile devices
- **Accuracy**: High confidence (>0.5) for clear currency images
- **False Positives**: Minimized by NMS and confidence threshold
- **Real-time**: Smooth live detection experience

## ðŸŽ¨ Visual Indicators

### Scanner Screen UI
- **Top Right**: Pipeline status with 6 steps shown
- **Bottom Panel**: Detection count and top 3 detections
- **Overlay**: Colored bounding boxes on detected objects
- **Labels**: Object name + confidence percentage

### Color Coding
- **Green (High)**: Confidence > 0.7
- **Yellow (Medium)**: Confidence 0.4-0.7
- **Red (Low)**: Confidence < 0.4

---

**Last Updated**: January 4, 2026  
**Model Version**: YOLOv8 Float32 TFLite  
**Target Platform**: Flutter (Android/iOS)
